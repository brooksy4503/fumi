import {
    ModelMetadata,
    ModelInput,
    ImageGenerationModel,
    VideoGenerationModel,
    TextToSpeechModel,
    SpeechToTextModel,
    AudioGenerationModel,
    ImageEditingModel,
    ModelLimits,
    ModelStatus,
} from '../types/fal-models';

/**
 * Model registry containing configurations for popular Fal models
 */
const modelRegistry: Record<string, ModelMetadata> = {
    // ============================================================================
    // IMAGE GENERATION MODELS
    // ============================================================================

    'stability-ai/stable-diffusion-xl-1.0': {
        id: 'stability-ai/stable-diffusion-xl-1.0',
        name: 'Stable Diffusion XL 1.0',
        description: 'High-quality image generation model with excellent prompt following and composition',
        category: 'image-generation',
        version: '1.0',
        provider: 'Stability AI',
        capabilities: ['text-to-image', 'image-to-image', 'inpainting', 'outpainting'],
        limits: {
            maxInputSize: '2048x2048',
            maxOutputSize: '2048x2048',
            rateLimit: {
                requestsPerMinute: 60,
                requestsPerHour: 1000,
            },
            costPerRequest: 0.02,
        },
        requiresAuth: true,
        status: 'active',
        supportedInputs: {
            textPrompt: true,
            imagePrompt: true,
            negativePrompt: true,
            dimensions: true,
            aspectRatios: ['1:1', '16:9', '9:16', '4:3', '3:4'],
            styles: ['realistic', 'anime', 'artistic', 'photorealistic'],
            controlNet: true,
        },
        supportedOutputs: {
            formats: ['png', 'jpg', 'webp'],
            maxResolution: '2048x2048',
            batchSize: 4,
        },
    } as ImageGenerationModel,

    'openai/dall-e-3': {
        id: 'openai/dall-e-3',
        name: 'DALL-E 3',
        description: 'OpenAI\'s advanced image generation model with superior understanding of complex prompts',
        category: 'image-generation',
        version: '3.0',
        provider: 'OpenAI',
        capabilities: ['text-to-image', 'variations', 'edits'],
        limits: {
            maxInputSize: '1024x1024',
            maxOutputSize: '1024x1024',
            rateLimit: {
                requestsPerMinute: 50,
                requestsPerHour: 500,
            },
            costPerRequest: 0.04,
        },
        requiresAuth: true,
        status: 'active',
        supportedInputs: {
            textPrompt: true,
            imagePrompt: false,
            negativePrompt: true,
            dimensions: true,
            aspectRatios: ['1:1', '16:9', '9:16'],
            styles: ['natural', 'vivid'],
            controlNet: false,
        },
        supportedOutputs: {
            formats: ['png', 'jpg'],
            maxResolution: '1024x1024',
            batchSize: 1,
        },
    } as ImageGenerationModel,

    'fal-ai/flux/schnell': {
        id: 'fal-ai/flux/schnell',
        name: 'Flux.1 Dev',
        description: 'Fast and efficient image generation with high quality outputs',
        category: 'image-generation',
        version: '1.0',
        provider: 'Black Forest Labs',
        capabilities: ['text-to-image', 'image-to-image'],
        limits: {
            maxInputSize: '2048x2048',
            maxOutputSize: '2048x2048',
            rateLimit: {
                requestsPerMinute: 100,
                requestsPerHour: 2000,
            },
            costPerRequest: 0.01,
        },
        requiresAuth: true,
        status: 'active',
        supportedInputs: {
            textPrompt: true,
            imagePrompt: true,
            negativePrompt: true,
            dimensions: true,
            aspectRatios: ['1:1', '16:9', '9:16', '4:3', '3:4'],
            styles: ['realistic', 'anime', 'cyberpunk'],
            controlNet: false,
        },
        supportedOutputs: {
            formats: ['png', 'jpg', 'webp'],
            maxResolution: '2048x2048',
            batchSize: 8,
        },
    } as ImageGenerationModel,

    // ============================================================================
    // VIDEO GENERATION MODELS
    // ============================================================================

    'sora': {
        id: 'sora',
        name: 'Sora',
        description: 'OpenAI\'s text-to-video model capable of creating realistic videos from text prompts',
        category: 'video-generation',
        version: '1.0',
        provider: 'OpenAI',
        capabilities: ['text-to-video', 'image-to-video'],
        limits: {
            maxInputSize: '1920x1080',
            maxOutputSize: '1920x1080',
            rateLimit: {
                requestsPerMinute: 10,
                requestsPerHour: 100,
            },
            costPerRequest: 0.10,
        },
        requiresAuth: true,
        status: 'active',
        supportedInputs: {
            textPrompt: true,
            videoPrompt: false,
            imagePrompt: true,
            negativePrompt: true,
            durations: [5, 10, 15],
            dimensions: true,
            aspectRatios: ['16:9', '9:16', '1:1'],
            fps: [24, 30],
        },
        supportedOutputs: {
            formats: ['mp4'],
            maxResolution: '1920x1080',
            maxDuration: 15,
            batchSize: 1,
        },
    } as VideoGenerationModel,

    'runway-gen-2': {
        id: 'runway-gen-2',
        name: 'Runway Gen-2',
        description: 'Advanced video generation model with motion control and image-to-video capabilities',
        category: 'video-generation',
        version: '2.0',
        provider: 'Runway ML',
        capabilities: ['text-to-video', 'image-to-video', 'video-to-video'],
        limits: {
            maxInputSize: '1024x576',
            maxOutputSize: '1024x576',
            rateLimit: {
                requestsPerMinute: 20,
                requestsPerHour: 200,
            },
            costPerRequest: 0.08,
        },
        requiresAuth: true,
        status: 'active',
        supportedInputs: {
            textPrompt: true,
            videoPrompt: true,
            imagePrompt: true,
            negativePrompt: true,
            durations: [5, 10],
            dimensions: true,
            aspectRatios: ['16:9'],
            fps: [8, 15],
        },
        supportedOutputs: {
            formats: ['mp4', 'webm'],
            maxResolution: '1024x576',
            maxDuration: 10,
            batchSize: 1,
        },
    } as VideoGenerationModel,

    'stable-video-diffusion': {
        id: 'stable-video-diffusion',
        name: 'Stable Video Diffusion',
        description: 'Video generation model based on Stable Diffusion architecture',
        category: 'video-generation',
        version: '1.0',
        provider: 'Stability AI',
        capabilities: ['image-to-video'],
        limits: {
            maxInputSize: '1024x576',
            maxOutputSize: '1024x576',
            rateLimit: {
                requestsPerMinute: 30,
                requestsPerHour: 300,
            },
            costPerRequest: 0.05,
        },
        requiresAuth: true,
        status: 'active',
        supportedInputs: {
            textPrompt: false,
            videoPrompt: false,
            imagePrompt: true,
            negativePrompt: true,
            durations: [2, 4, 8, 16],
            dimensions: true,
            aspectRatios: ['16:9'],
            fps: [8],
        },
        supportedOutputs: {
            formats: ['mp4'],
            maxResolution: '1024x576',
            maxDuration: 16,
            batchSize: 1,
        },
    } as VideoGenerationModel,

    // ============================================================================
    // TEXT-TO-SPEECH MODELS
    // ============================================================================

    'openai/tts': {
        id: 'openai/tts',
        name: 'OpenAI Text-to-Speech',
        description: 'High-quality text-to-speech with natural voice synthesis',
        category: 'text-to-speech',
        version: '1.0',
        provider: 'OpenAI',
        capabilities: ['text-to-speech', 'voice-cloning'],
        limits: {
            maxInputSize: '4096 characters',
            rateLimit: {
                requestsPerMinute: 100,
                requestsPerHour: 1000,
            },
            costPerRequest: 0.015,
        },
        requiresAuth: true,
        status: 'active',
        voices: [
            {
                id: 'alloy',
                name: 'Alloy',
                gender: 'neutral',
                age: 'young',
                quality: 'premium',
            },
            {
                id: 'echo',
                name: 'Echo',
                gender: 'male',
                age: 'young',
                quality: 'premium',
            },
            {
                id: 'fable',
                name: 'Fable',
                gender: 'female',
                age: 'young',
                quality: 'premium',
            },
            {
                id: 'onyx',
                name: 'Onyx',
                gender: 'male',
                age: 'adult',
                quality: 'premium',
            },
            {
                id: 'nova',
                name: 'Nova',
                gender: 'female',
                age: 'young',
                quality: 'premium',
            },
            {
                id: 'shimmer',
                name: 'Shimmer',
                gender: 'female',
                age: 'adult',
                quality: 'premium',
            },
        ],
        languages: ['en', 'es', 'fr', 'de', 'it', 'pt', 'pl', 'tr', 'ru', 'nl', 'cs', 'ar', 'zh-cn', 'hu', 'ko', 'ja'],
        supportedFormats: ['mp3', 'opus', 'aac', 'flac'],
        maxTextLength: 4096,
        speedRange: {
            min: 0.25,
            max: 4.0,
        },
        features: {
            emotions: true,
            multiSpeaker: false,
            customVoices: false,
            voiceCloning: true,
        },
    } as TextToSpeechModel,

    'elevenlabs-tts': {
        id: 'elevenlabs-tts',
        name: 'ElevenLabs Text-to-Speech',
        description: 'Emotionally expressive text-to-speech with voice cloning capabilities',
        category: 'text-to-speech',
        version: '2.0',
        provider: 'ElevenLabs',
        capabilities: ['text-to-speech', 'voice-cloning', 'emotion-control'],
        limits: {
            maxInputSize: '5000 characters',
            rateLimit: {
                requestsPerMinute: 50,
                requestsPerHour: 500,
            },
            costPerRequest: 0.02,
        },
        requiresAuth: true,
        status: 'active',
        voices: [
            {
                id: '21m00Tcm4TlvDq8ikWAM',
                name: 'Rachel',
                gender: 'female',
                age: 'young',
                quality: 'premium',
            },
            {
                id: '29vD33N1CtxCmqQRPOHJ',
                name: 'Drew',
                gender: 'male',
                age: 'young',
                quality: 'premium',
            },
            {
                id: 'AZnzlk1XvdvUeBnXmlld',
                name: 'Domi',
                gender: 'female',
                age: 'young',
                quality: 'premium',
            },
        ],
        languages: ['en', 'es', 'fr', 'de', 'pt', 'it', 'pl', 'tr', 'ru', 'nl', 'cs', 'ar', 'zh-cn', 'ja', 'hu', 'hi'],
        supportedFormats: ['mp3', 'wav'],
        maxTextLength: 5000,
        speedRange: {
            min: 0.5,
            max: 2.0,
        },
        features: {
            emotions: true,
            multiSpeaker: true,
            customVoices: true,
            voiceCloning: true,
        },
    } as TextToSpeechModel,

    // ============================================================================
    // SPEECH-TO-TEXT MODELS
    // ============================================================================

    'whisper-large-v3': {
        id: 'whisper-large-v3',
        name: 'Whisper Large v3',
        description: 'OpenAI\'s advanced speech recognition model with high accuracy across languages',
        category: 'speech-to-text',
        version: '3.0',
        provider: 'OpenAI',
        capabilities: ['speech-to-text', 'language-detection', 'timestamps'],
        limits: {
            maxInputSize: '25MB',
            maxOutputSize: '25MB',
            rateLimit: {
                requestsPerMinute: 100,
                requestsPerHour: 1000,
            },
            costPerRequest: 0.006,
        },
        requiresAuth: true,
        status: 'active',
        supportedFormats: ['mp3', 'mp4', 'mpeg', 'mpga', 'm4a', 'wav', 'flac'],
        languages: ['en', 'zh', 'de', 'es', 'ru', 'ko', 'fr', 'ja', 'pt', 'tr', 'pl', 'ca', 'nl', 'ar', 'sv', 'it', 'id', 'hi', 'fi', 'vi', 'he', 'uk', 'el', 'ms', 'cs', 'ro', 'da', 'hu', 'ta', 'no', 'th', 'ur', 'hr', 'bg', 'lt', 'la', 'mi', 'ml', 'cy', 'sk', 'te', 'fa', 'lv', 'bn', 'sr', 'az', 'sl', 'kn', 'et', 'mk', 'br', 'eu', 'is', 'hy', 'ne', 'mn', 'bs', 'kk', 'sq', 'sw', 'gl', 'mr', 'pa', 'si', 'km', 'sn', 'yo', 'so', 'af', 'oc', 'ka', 'be', 'tg', 'sd', 'gu', 'am', 'yi', 'lo', 'uz', 'fo', 'ht', 'ps', 'tk', 'nn', 'mt', 'sa', 'lb', 'my', 'bo', 'tl', 'mg', 'as', 'tt', 'haw', 'ln', 'ha', 'ba', 'jw', 'su'],
        maxDuration: 1800, // 30 minutes
        features: {
            timestamps: true,
            diarization: false,
            multipleLanguages: true,
            customVocabulary: false,
        },
        modelSizes: ['large'],
    } as SpeechToTextModel,

    // ============================================================================
    // AUDIO GENERATION MODELS
    // ============================================================================

    'musicgen-large': {
        id: 'musicgen-large',
        name: 'MusicGen Large',
        description: 'Meta\'s music generation model that creates music from text descriptions',
        category: 'audio-generation',
        version: '1.0',
        provider: 'Meta',
        capabilities: ['text-to-music', 'continuation'],
        limits: {
            maxInputSize: '512 tokens',
            rateLimit: {
                requestsPerMinute: 20,
                requestsPerHour: 200,
            },
            costPerRequest: 0.05,
        },
        requiresAuth: true,
        status: 'active',
        supportedFormats: ['mp3', 'wav', 'flac'],
        sampleRates: [22050, 44100, 48000],
        maxDuration: 30,
        genres: ['classical', 'electronic', 'rock', 'pop', 'jazz', 'hip-hop'],
        features: {
            textToMusic: true,
            genreControl: true,
            moodControl: true,
            instrumentControl: true,
            bpmControl: true,
        },
    } as AudioGenerationModel,

    // ============================================================================
    // IMAGE EDITING MODELS
    // ============================================================================

    // Note: ImageEditingModel type definition may be incomplete in the types file
    // 'stable-diffusion-inpainting': {
    //     id: 'stable-diffusion-inpainting',
    //     name: 'Stable Diffusion Inpainting',
    //     description: 'Advanced inpainting model for image editing and restoration',
    //     category: 'image-editing',
    //     version: '1.0',
    //     provider: 'Stability AI',
    //     capabilities: ['inpainting', 'outpainting', 'object-removal'],
    //     limits: {
    //         maxInputSize: '2048x2048',
    //         maxOutputSize: '2048x2048',
    //         rateLimit: {
    //             requestsPerMinute: 60,
    //             requestsPerHour: 1000,
    //         },
    //         costPerRequest: 0.02,
    //     },
    //     requiresAuth: true,
    //     status: 'active',
    // } as any, // Using any due to type definition issues
};

/**
 * Get a model by its ID
 */
export function getModel(id: string): ModelMetadata | undefined {
    return modelRegistry[id];
}

/**
 * Get all models
 */
export function getAllModels(): ModelMetadata[] {
    return Object.values(modelRegistry);
}

/**
 * Get models by category
 */
export function getModelsByCategory(category: ModelMetadata['category']): ModelMetadata[] {
    return Object.values(modelRegistry).filter(model => model.category === category);
}

/**
 * Check if a model exists
 */
export function modelExists(id: string): boolean {
    return id in modelRegistry;
}

/**
 * Get default parameters for a model
 */
export function getDefaultParams(id: string): Partial<ModelInput> | null {
    const model = modelRegistry[id];
    if (!model) return null;

    switch (model.category) {
        case 'image-generation':
            return {
                width: 1024,
                height: 1024,
                numImages: 1,
                guidanceScale: 7.5,
                numInferenceSteps: 20,
                quality: 'standard',
                format: 'png',
            };
        case 'video-generation':
            return {
                duration: 5,
                width: 1024,
                height: 576,
                fps: 8,
                numVideos: 1,
                guidanceScale: 7.5,
                numInferenceSteps: 20,
                quality: 'standard',
            };
        case 'text-to-speech':
            return {
                speed: 1.0,
                pitch: 0,
                volume: 1.0,
                format: 'mp3',
            };
        case 'speech-to-text':
            return {
                includeTimestamps: false,
                diarize: false,
                model: 'large',
                temperature: 0,
            };
        case 'audio-generation':
            return {
                duration: 10,
                format: 'mp3',
                sampleRate: 44100,
            };
        case 'image-editing':
            return {
                strength: 0.75,
                guidanceScale: 7.5,
                numInferenceSteps: 20,
            };
        default:
            return {};
    }
}

/**
 * Validate input parameters for a model
 */
export function validateInput(id: string, input: ModelInput): { valid: boolean; errors: string[] } {
    const model = modelRegistry[id];
    if (!model) {
        return { valid: false, errors: [`Model ${id} not found`] };
    }

    const errors: string[] = [];

    // Category-specific validation
    switch (model.category) {
        case 'image-generation': {
            const imgInput = input as any;
            if (!imgInput.prompt) errors.push('Prompt is required');
            if (imgInput.width && imgInput.height) {
                const maxRes = model.supportedOutputs.maxResolution;
                const [maxW, maxH] = maxRes.split('x').map(Number);
                if (imgInput.width > maxW || imgInput.height > maxH) {
                    errors.push(`Dimensions exceed maximum resolution ${maxRes}`);
                }
            }
            break;
        }
        case 'video-generation': {
            const vidInput = input as any;
            if (!vidInput.prompt) errors.push('Prompt is required');
            if (vidInput.duration && !model.supportedInputs.durations.includes(vidInput.duration)) {
                errors.push(`Duration not supported. Available: ${model.supportedInputs.durations.join(', ')}`);
            }
            break;
        }
        case 'text-to-speech': {
            const ttsInput = input as any;
            if (!ttsInput.text) errors.push('Text is required');
            if (ttsInput.text.length > model.maxTextLength) {
                errors.push(`Text exceeds maximum length of ${model.maxTextLength} characters`);
            }
            break;
        }
        case 'speech-to-text': {
            const sttInput = input as any;
            if (!sttInput.audio) errors.push('Audio is required');
            break;
        }
        case 'audio-generation': {
            const audioInput = input as any;
            if (!audioInput.prompt) errors.push('Prompt is required');
            break;
        }
        case 'image-editing': {
            const editInput = input as any;
            if (!editInput.imageUrl) errors.push('Image URL is required');
            break;
        }
    }

    return { valid: errors.length === 0, errors };
}

export default modelRegistry;